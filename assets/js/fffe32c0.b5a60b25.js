"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[768],{3613:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>o,contentTitle:()=>s,default:()=>m,frontMatter:()=>r,metadata:()=>i,toc:()=>u});var n=a(7462),l=(a(7294),a(3905));const r={sidebar_position:1,slug:"/"},s="Documentation",i={unversionedId:"Documentation",id:"Documentation",title:"Documentation",description:"Downloading and visualizing the data",source:"@site/docs/Documentation.md",sourceDirName:".",slug:"/",permalink:"/PRML_minor_project/",draft:!1,tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1,slug:"/"},sidebar:"tutorialSidebar"},o={},u=[{value:"Downloading and visualizing the data",id:"downloading-and-visualizing-the-data",level:2},{value:"Preprocessing the data",id:"preprocessing-the-data",level:2},{value:"Kmeans Clustering",id:"kmeans-clustering",level:2},{value:"Hierarchical clustering",id:"hierarchical-clustering",level:2},{value:"DBSCAN clustering",id:"dbscan-clustering",level:2}],p={toc:u},c="wrapper";function m(e){let{components:t,...a}=e;return(0,l.kt)(c,(0,n.Z)({},p,a,{components:t,mdxType:"MDXLayout"}),(0,l.kt)("h1",{id:"documentation"},"Documentation"),(0,l.kt)("h2",{id:"downloading-and-visualizing-the-data"},"Downloading and visualizing the data"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre"},"import pandas as pd\ndata = pd.read_csv('/content/Country-data.csv')   #downloading the dataset\ndata\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Downloaded the dataset using",(0,l.kt)("strong",{parentName:"li"}," pd.read_csv")," using pandas library.")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre"},"data[['exports','health','imports']] = data[['exports','health','imports']].apply(lambda x : x*data[\"gdpp\"]/100)    #multiplying by %age GDP\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Multiplied by %age Gdp using ",(0,l.kt)("strong",{parentName:"li"},"lambda")," x function")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"data.isna().sum()\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"checking for total  null values in each column using data",(0,l.kt)("strong",{parentName:"li"},".isna().sum()"))),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"len(data['country'].unique()) == len(data)\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"checking repetitions in country column using ",(0,l.kt)("strong",{parentName:"li"},".unique()")," function")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"data.shape\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"using ",(0,l.kt)("strong",{parentName:"li"},".shape")," to check the dimensions of dataset")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"data.dtypes\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"using ",(0,l.kt)("strong",{parentName:"li"},".dtypes")," to check the datatypes of each column")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"data.describe()\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"using ",(0,l.kt)("strong",{parentName:"li"},".describe()")," to do statistical analysis of dataset")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"df = data.drop('country', axis=1)\ncolumns = df.columns\ncolumns\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"using ",(0,l.kt)("strong",{parentName:"li"},".drop")," to drop coutry column from dataset")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nfig, ax = plt.subplots(nrows=3, ncols=3, figsize=(15, 15))\nfor i in range(9):\n  plt.subplot(3,3,i+1)         #i+1 because we want to start with 1 (3, 3, 1)\n  sns.histplot(df[columns[i]])    #plotting histograms\nplt.show()\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"using ",(0,l.kt)("strong",{parentName:"li"},"matplotlib")," and ",(0,l.kt)("strong",{parentName:"li"},"seaborn")," to plot the histogram of each column using ",(0,l.kt)("strong",{parentName:"li"},"sns.histplot"))),(0,l.kt)("p",null,"Similarly plotted ",(0,l.kt)("strong",{parentName:"p"},"rest of the columns")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"plt.figure(figsize=(10,10))\ncorr = data.corr()\nsns.heatmap(corr, annot=True)   \n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"using ",(0,l.kt)("strong",{parentName:"li"},"matplotlib")," to create heatmap to visualise correlation matrix"),(0,l.kt)("li",{parentName:"ul"},"calculated corr matrix using ",(0,l.kt)("strong",{parentName:"li"},"data.corr()")," function and visulaised using ",(0,l.kt)("strong",{parentName:"li"},"sns.heatmap()")," function")),(0,l.kt)("h2",{id:"preprocessing-the-data"},"Preprocessing the data"),(0,l.kt)("p",null,"Run the development server:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nnew = scaler.fit_transform(df)   #standardising the numerical data\nnewdf = pd.DataFrame(data= new , columns = columns)   \nnewdf\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"used ",(0,l.kt)("strong",{parentName:"li"},"StandardScaler")," from ",(0,l.kt)("strong",{parentName:"li"},"sklear.processing library")," to scale the data using ",(0,l.kt)("strong",{parentName:"li"},"scaler.fit_transform()")," method"),(0,l.kt)("li",{parentName:"ul"},"created a new Dataframe using ",(0,l.kt)("strong",{parentName:"li"},"pd.DataFrame()"))),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"from sklearn.decomposition import PCA\nimport numpy as np\n\npca = PCA()\npca.fit(newdf)    \npca_data_standard = pca.transform(newdf)\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"used ",(0,l.kt)("strong",{parentName:"li"},"PCA")," from ",(0,l.kt)("strong",{parentName:"li"},"sklearn.decomposition library")," and transformed the data using ",(0,l.kt)("strong",{parentName:"li"},"pca.transform()")),(0,l.kt)("li",{parentName:"ul"},"imported ",(0,l.kt)("strong",{parentName:"li"},"numpy")," library as np")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"var = np.round(pca.explained_variance_ratio_*100, decimals=2) \nl = len(var)\nlabels = ['PC' + str(x) for x in range (1, l+1)]      #creating a list of labels for each principal component\nplt.bar(x=range(1,l+1), height=var, tick_label = labels)   #plotting the variance\nplt.ylabel('Percentage of Explained Variance')\nplt.xlabel('Principal Component')\nplt.show()\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"used ",(0,l.kt)("strong",{parentName:"li"},"pca.explained",(0,l.kt)("em",{parentName:"strong"},"variance_ratio")),"  to calculating the %age of explained variance for each principal component"),(0,l.kt)("li",{parentName:"ul"},"used ",(0,l.kt)("strong",{parentName:"li"},"np.round()")," to round decimal to two places"),(0,l.kt)("li",{parentName:"ul"},"plotted the bargraph of each component using ",(0,l.kt)("strong",{parentName:"li"},"mathplotlib"))),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"pca_df = pd.DataFrame(pca_data_standard, columns=labels)\nplt.scatter(pca_df.PC1, pca_df.PC2, color='black', edgecolors='pink')  #scatter plot to visualise projection of data onto first two PC obtained from PCA\nplt.title('PCA')\nplt.xlabel(f'PC1 - {var[0]}%')\nplt.ylabel(f'PC2 - {var[1]}%')\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"used ",(0,l.kt)("strong",{parentName:"li"},"plt.scatter")," from ",(0,l.kt)("strong",{parentName:"li"},"mathplotlib")," to plot the  scatter plot to visualise projection of data onto first two PC obtained from PCA")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"pca_df.drop(['PC5','PC6','PC7','PC8','PC9'], axis = 1, inplace=True)\npca_df\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"removed unnecessaty principal components using ",(0,l.kt)("strong",{parentName:"li"},"df.drop()"))),(0,l.kt)("h2",{id:"kmeans-clustering"},"Kmeans Clustering"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"from sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\nsil=[]\nfor k in range(2, 11):\n  kmeans = KMeans(n_clusters=k, init='random', n_init=10, max_iter=300).fit(pca_df)   #KMeans class is instantiated with the number of clusters specified by k\n  labels = kmeans.labels_     #resulting cluster labels from the model\n  sil.append(silhouette_score(pca_df, labels, metric = 'euclidean'))   #appending silhouette score for each 'k' in the list\nsns.lineplot(x = range(2, 11), y = sil);\nplt.xlabel('Number of clusters')\nplt.ylabel('Silhouette score')\nplt.show()\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"imported ",(0,l.kt)("strong",{parentName:"li"},"Kmeans")," from ",(0,l.kt)("strong",{parentName:"li"},"sklearn.cluster")," library and ",(0,l.kt)("strong",{parentName:"li"},"silhouette_score")," from ",(0,l.kt)("strong",{parentName:"li"},"sklearn.metrics")," library"),(0,l.kt)("li",{parentName:"ul"},"The ",(0,l.kt)("strong",{parentName:"li"},"silhouette score")," measures how similar an object is to its own cluster compared to other clusters. A higher silhouette score indicates better clustering."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"n_clusters")," (int) - the number of clusters to form as well as the number of centroids to generate."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"n_init (int)")," - the number of time the k-means algorithm will be run with different centroid seeds."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"max_iter (int)")," - the maximum number of iterations of the k-means algorithm for a single run."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"labels")," (array-like) - the resulting cluster labels from the model."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"metric")," (string) - the distance metric to use. 'euclidean' is the default metric."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"sil")," (list) - a list containing the silhouette score for each number of clusters."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"sns.lineplot")," (Line plot object) - a line plot showing the silhouette score for each number of clusters."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"init"),"(string) - the method used to initialize the centroids. 'random' selects random data points as initial centroids."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},".fit()")," used to fit the dataset")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"from sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\nsse = []\nfor i in range(1, 11):\n  kmeans = KMeans(n_clusters=i, init='random', n_init=10, max_iter=300).fit(pca_df)\n  sse.append(kmeans.inertia_)       #appending sum of squared errors for each 'k' in the list\n\nplt.plot(range(1, 11), sse, marker='o')\nplt.xlabel('Number of clusters')\nplt.ylabel('Sum of squared errors')\nplt.show()\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"inertia"),"(float) - the within-cluster sum of squares (inertia) of KMeans clustering for the input data."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"sse")," gives the sum of squared errors for each 'k' in the list")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"kmeans = KMeans(n_clusters=4, init='random', n_init=10, max_iter=300, random_state=0)\nkmeans.fit(pca_df)\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"created new ",(0,l.kt)("strong",{parentName:"li"},"kmeans")," object and fitted the dataset")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"cluster = kmeans.fit_predict(pca_df)\ncluster\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"cluster"),"(array-like) - an array containing the predicted clusters for each data point in the input data.")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},'unique_cluster, counts = np.unique(cluster, return_counts=True)\npercentages = counts / len(cluster) * 100\n\nprint("Number of samples:")\nfor i, label in enumerate(unique_cluster):    #calculated number of samples for each cluster\n  print(f"Cluster {label}: {counts[i]}")\nprint("")\n\nprint("Percentage:")\nfor i, label in enumerate(unique_cluster):\n  print(f"Cluster {label}: {percentages[i]:.2f}%")\n')),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"unique_cluster")," (array-like) - an array containing the unique predicted clusters."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"counts")," (array-like) - an array containing the count of samples for each predicted cluster."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"percentages")," (array-like) - an array containing the percentage of samples for each predicted cluster.")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"silhouette_score(pca_df, cluster, metric = 'euclidean')\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"calculated score")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"df_cluster = data\ndf_cluster['cluster']=cluster  \ndf_cluster\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"assigned the cluster to original dataset")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (15,5))\n\nplt.subplot(1,2,1)\nsns.boxplot(x='cluster', y='child_mort', data=df_cluster);\nplt.title('child_mort vs cluster')\n\nplt.subplot(1,2,2)\nsns.boxplot(x='cluster', y='income', data=df_cluster);\nplt.title('income vs cluster')\n\nplt.show()\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"plotted boxplot  suing ",(0,l.kt)("strong",{parentName:"li"},"sns.boxplot()"))),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"df_cluster['cluster'] = df_cluster['cluster'].replace([3], 1)\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"used ",(0,l.kt)("strong",{parentName:"li"},".replace()")," to repalce value")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"df_cluster['cluster'].loc[df_cluster['cluster'] == 0] = 'Need Help'\ndf_cluster['cluster'].loc[df_cluster['cluster'] == 1] = 'No Help Needed'\ndf_cluster['cluster'].loc[df_cluster['cluster'] == 2] = 'Might Need Help'\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"This code modifies the values in the 'cluster' column of the input DataFrame df_cluster. Each occurrence of a specific value (0, 1, or 2) is replaced with a corresponding new value (Need Help, No Help Needed, or Might Need Help)")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"import plotly.express as px\nfig = px.choropleth(df_cluster[['country','cluster']],\n                    locationmode = 'country names',\n                    locations = 'country',\n                    color = df_cluster['cluster'],\n                    color_discrete_map = {'Need Help':'Red',\n                                          'Might Need Help':'Yellow',\n                                          'No Help Needed': 'Blue'})\nfig.update_geos(fitbounds = \"locations\", visible = True)\nfig.show(engine = 'kaleido')\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"used ",(0,l.kt)("strong",{parentName:"li"},"px")," from ",(0,l.kt)("strong",{parentName:"li"},"plotly.express")," library to plot countries"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"df_cluster")," (DataFrame) - the input DataFrame containing the data to be visualized."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"locationmode")," (str) - the location mode to use for the choropleth map (e.g. 'country names', 'ISO-3', etc.)."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"color")," (str) - the column in df_cluster that contains the data to be plotted as the color of the map."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"color_discrete_map")," (dict) - a dictionary mapping each unique value in the color column to a specific color."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"fig")," (Figure) - a Plotly figure object representing the choropleth map."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},'fig.update_geos(fitbounds = "locations", visible = True)')," sets the fitbounds and visible parameters of the update_geos() method of the fig object. This modifies the appearance and behavior of the map, allowing it to display more effectively."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"fig.show(engine = 'kaleido')")," displays the map using the kaleido engine, which is a vector graphics rendering engine that can be used to save high-quality static images of Plotly figures. The show() method opens a window in the browser, displaying the map.")),(0,l.kt)("p",null,"Similarly plotted ",(0,l.kt)("strong",{parentName:"p"},"rest of the continents")),(0,l.kt)("h2",{id:"hierarchical-clustering"},"Hierarchical clustering"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"from scipy.cluster.hierarchy import dendrogram, linkage\n\nZ = linkage(pca_df, method='ward', metric='euclidean')   #created a linkage matrix\n\nplt.figure(figsize=(25,8))\nplt.title('Hierarchical Clustering Dendrogram')\nplt.xlabel('Sample Index')\nplt.ylabel('Distance')\ndendrogram(Z)    #plotting a dendogram\nplt.show()\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"from ",(0,l.kt)("strong",{parentName:"li"},"scipy.cluster.hierarchy import dendrogram, linkage")," imports the ",(0,l.kt)("strong",{parentName:"li"},"dendrogram()")," and l",(0,l.kt)("strong",{parentName:"li"},"inkage()")," functions from the scipy.cluster.hierarchy module."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"Z = linkage(pca_df, method='ward', metric='euclidean')")," calculates the hierarchical clustering linkage matrix Z using the ",(0,l.kt)("strong",{parentName:"li"},"Ward method")," and ",(0,l.kt)("strong",{parentName:"li"},"Euclidean distance metric"),".\n-",(0,l.kt)("strong",{parentName:"li"},"dendrogram(Z)")," generates and plots a dendrogram using the linkage matrix Z.")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"from sklearn.cluster import AgglomerativeClustering\nnp.random.seed(0)\nclustering = AgglomerativeClustering(n_clusters=3, metric='euclidean')\nclustering.fit(pca_df)\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"from sklearn.cluster import AgglomerativeClustering"),"imports the AgglomerativeClustering class from sklearn.cluster module."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"np.random.seed(0"),") sets the random seed to 0 for reproducibility."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"clustering = AgglomerativeClustering(n_clusters=3, metric='euclidean')")," instantiates an AgglomerativeClustering object with ",(0,l.kt)("strong",{parentName:"li"},"n_clusters"),"=3 and ",(0,l.kt)("strong",{parentName:"li"},"metric"),"='euclidean'. This creates a hierarchical clustering model that will group samples into 3 clusters based on the Euclidean distance between the samples."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"clustering.fit(pca_df)")," fits the hierarchical clustering model to the pca_df dataset, grouping the samples into 3 clusters based on the Euclidean distance between the samples.")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"cluster2 = clustering.fit_predict(pca_df)\ncluster2\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"cluster2 = clustering.fit_predict(pca_df)")," assigns each sample to a cluster based on the hierarchical clustering model, and returns an array of cluster assignments for each sample in the dataset. The resulting array ",(0,l.kt)("strong",{parentName:"li"},"cluster2")," contains the cluster assignments of each sample in the ",(0,l.kt)("strong",{parentName:"li"},"pca_df")," dataset.")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},'unique_cluster, counts = np.unique(cluster2, return_counts=True)\npercentages = counts / len(cluster2) * 100\n\nprint("Number of samples:")\nfor i, label in enumerate(unique_cluster):    #calculated number of samples for each cluster\n  print(f"Cluster {label}: {counts[i]}")\nprint("")\n\nprint("Percentage:")\nfor i, label in enumerate(unique_cluster):\n  print(f"Cluster {label}: {percentages[i]:.2f}%")\n')),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"calculated cluster counts using ",(0,l.kt)("strong",{parentName:"li"},"np.unique()")," function and calculated percentages")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"df_cluster2 = data\ndf_cluster2['cluster']=cluster2   #assigned the cluster to original dataset\ndf_cluster2\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"assigned the cluster to original dataset")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (15,5))\n\nplt.subplot(1,2,1)\nsns.boxplot(x='cluster', y='child_mort', data=df_cluster2);\nplt.title('child_mort vs cluster')\n\nplt.subplot(1,2,2)\nsns.boxplot(x='cluster', y='income', data=df_cluster2);\nplt.title('income vs cluster')\n\nplt.show()\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"plotted boxplot using ",(0,l.kt)("strong",{parentName:"li"},"sns.boxplot()"))),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"df_cluster2['cluster'].loc[df_cluster2['cluster'] == 0] = 'No Help Needed'\ndf_cluster2['cluster'].loc[df_cluster2['cluster'] == 1] = 'Need Help'\ndf_cluster2['cluster'].loc[df_cluster2['cluster'] == 2] = 'Might Need Help'\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"similar to step done before assigned new names to clusters")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},'sns.pairplot(df_cluster2, hue = "cluster")\n')),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"The ",(0,l.kt)("strong",{parentName:"li"},"sns.pairplot()")," function creates a matrix of scatter plots for all pairs of features in a dataset."),(0,l.kt)("li",{parentName:"ul"},"each point is colored according to cluster using  ",(0,l.kt)("strong",{parentName:"li"},"hue")," parameter")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"import plotly.express as px\nfig = px.choropleth(df_cluster2[['country','cluster']],\n                    locationmode = 'country names',\n                    locations = 'country',\n                    color = df_cluster2['cluster'],\n                    color_discrete_map = {'Need Help':'Red',\n                                          'Might Need Help':'Yellow',\n                                          'No Help Needed': 'Blue'})\nfig.update_geos(fitbounds = \"locations\", visible = True)\nfig.show(engine = 'kaleido')\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"same steps as in Kmeans to visualise according to countries")),(0,l.kt)("p",null,"Similarly ",(0,l.kt)("strong",{parentName:"p"},"all continents")," are plotted"),(0,l.kt)("h2",{id:"dbscan-clustering"},"DBSCAN clustering"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"from sklearn.cluster import DBSCAN\n\neps_range = np.linspace(0.10, 1.00, num=100)\nmin_samples_range = range(2, 10)\ns=-np.inf\n\nfor eps in eps_range:\n  for min_samples in min_samples_range:\n    dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n    labels = dbscan.fit_predict(pca_df)\n    n_clusters = len(np.unique(labels)) - (1 if -1 in labels else 0)\n    n_noise = list(labels).count(-1)\n    if (n_clusters==2):                #calculated silhouette score whenever the number of clusters is equal to 3 (n_clusters=2 + one cluster for noise)\n      score = silhouette_score(pca_df, labels, metric = \"euclidean\")\n      print(f'eps={eps:.2f}, min_samples={min_samples}, n_clusters={n_clusters}, n_noise={n_noise}, silhouette_score={score}')\n      if (score>s):\n        final_eps = eps   \n        final_sample = min_samples    #updated the values of eps and min_samples if the score has improved\n        s=score\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"imported ",(0,l.kt)("strong",{parentName:"li"},"DBSCAN")," from ",(0,l.kt)("strong",{parentName:"li"},"sklearn.cluster")," library"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"np.linspace(start, stop, num)")," returns num evenly spaced numbers over the interval ","[start, stop]"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"dbscan = DBSCAN(eps=eps, min_samples=min_samples)")," creates a DBSCAN object with the specified eps and min_samples values. ",(0,l.kt)("strong",{parentName:"li"},"eps")," is the radius of the neighborhood around each point that will be considered to define the density of the points. ",(0,l.kt)("strong",{parentName:"li"},"min_samples")," is the minimum number of points required to form a dense region. If a point has fewer than min_samples neighbors within a distance of eps, it will be considered as noise."),(0,l.kt)("li",{parentName:"ul"},"This code performs hyperparameter tuning for the DBSCAN clustering algorithm. It first defines a range of values for the epsilon parameter (eps_range) and the minimum number of samples required to form a dense region (min_samples_range). It then loops over all combinations of these parameters, and for each combination, fits a DBSCAN model to the data and calculates the number of clusters, number of noise points, and the silhouette score. If the number of clusters is equal to 2 (plus one cluster for noise), the silhouette score is calculated using the silhouette_score function from scikit-learn. The combination of eps and min_samples that result in the highest silhouette score is then selected as the final hyperparameters, and their values are stored in the variables final_eps and final_sample, respectively.")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"from sklearn.cluster import DBSCAN\nnp.random.seed(0)\ndb = DBSCAN(eps=0.8818181818181817, min_samples=9).fit(pca_df)\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"This code initializes a DBSCAN clustering algorithm with eps=0.8818181818181817 and min_samples=9, and applies it to the pca_df dataset using the fit method. The resulting model is stored in the db variable.")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},'unique_cluster, counts = np.unique(cluster3, return_counts=True)\npercentages = counts / len(cluster3) * 100\n\nprint("Number of samples:")\nfor i, label in enumerate(unique_cluster):    #calculated number of samples for each cluster\n  print(f"Cluster {label}: {counts[i]}")\nprint("")\n\nprint("Percentage:")\nfor i, label in enumerate(unique_cluster):\n  print(f"Cluster {label}: {percentages[i]:.2f}%")\n')),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"calculated unique clusters similar to before algorithms")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"df_cluster3 = data\ndf_cluster3['cluster']=cluster3   \ndf_cluster3\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"assigned the cluster to original dataset")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (15,5))\n\nplt.subplot(1,2,1)\nsns.boxplot(x='cluster', y='child_mort', data=df_cluster3);\nplt.title('child_mort vs cluster')\n\nplt.subplot(1,2,2)\nsns.boxplot(x='cluster', y='income', data=df_cluster3);\nplt.title('income vs cluster')\n\nplt.show()\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"plotted box plots similar to before")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"df_cluster3['cluster'].loc[df_cluster3['cluster'] == -1] = 'Might Need Help'\ndf_cluster3['cluster'].loc[df_cluster3['cluster'] == 0] = 'Need Help'\ndf_cluster3['cluster'].loc[df_cluster3['cluster'] == 1] = 'No Help Needed'\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"asasigned name to clusters similar to before")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},'sns.pairplot(df_cluster3, hue = "cluster")\n')),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"visualises using pairplots")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"import plotly.express as px\nfig = px.choropleth(df_cluster3[['country','cluster']],\n                    locationmode = 'country names',\n                    locations = 'country',\n                    color = df_cluster3['cluster'],\n                    color_discrete_map = {'Need Help':'Red',\n                                          'Might Need Help':'Yellow',\n                                          'No Help Needed': 'Blue'})\nfig.update_geos(fitbounds = \"locations\", visible = True)\nfig.show(engine = 'kaleido')\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"plotted countries similar to before\nSimilarly plotted graph for ",(0,l.kt)("strong",{parentName:"li"},"each continent"))),(0,l.kt)("p",null,(0,l.kt)("strong",{parentName:"p"},"ALl the steps are then repeated for dataset without pca")))}m.isMDXComponent=!0}}]);